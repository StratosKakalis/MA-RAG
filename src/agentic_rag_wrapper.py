import os
import json
from langgraph.graph import StateGraph, START
from src.utils import GraphState
from agents.plan_executor import build_plan_executor
from agents.plan import plan_agent
from dotenv import load_dotenv

load_dotenv()

# ---------------------------
# Heavy initialization (do once)
# ---------------------------

# Initialize the plan executor agent
plan_executor_agent = build_plan_executor()

# Build the LangGraph workflow (Planner → Executor)
graph_builder = StateGraph(GraphState)
graph_builder.add_node("planer_node", plan_agent)

def plan_executor_node(state: GraphState):
    """Executes the reasoning plan generated by the planner."""
    input_data = {
        "original_question": state["original_question"],
        "plan": state["plan"],
        "stop": False
    }
    output = plan_executor_agent.invoke(input_data)
    return {"past_exp": [output]}

graph_builder.add_node("plan_executor_node", plan_executor_node)
graph_builder.add_edge(START, "planer_node")
graph_builder.add_edge("planer_node", "plan_executor_node")
graph = graph_builder.compile()


# ---------------------------
# Wrapper function for benchmarking
# ---------------------------

def agentic_rag_answer(question: str) -> str:
    """
    Wrapper function to call the Agentic RAG system.
    Accepts a question string, returns the final answer as a string.
    """
    question = question.strip()
    if not question.endswith("?"):
        question += "?"
    
    inputs = {"original_question": question}
    
    try:
        output = graph.invoke(inputs)
        # Extract final answer from past_exp -> [0] -> Plan Summary -> Answer
        past_exp = output.get("past_exp", [])
        if past_exp:
            plan_summary = past_exp[0].get("plan_summary", {})
            answer = plan_summary.get("answer", "")
        else:
            answer = ""
        return answer
    except Exception as e:
        print(f"❌ Error during Agentic RAG inference: {e}")
        return ""  # Return empty string on failure
